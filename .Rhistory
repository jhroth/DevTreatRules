low_coverage %>% filter(`Passed QC` == 1, Center == "BCM")
low_coverage %>% filter(`Passed QC` == 1, Center == "BCM") %>% summarize(mean_cov = mean(`Aligned Non Duplicated Coverage`))
low_coverage %>% filter(`Passed QC` == 1) %>% group_by(Center) %>%
summarize(mean_cov = mean(`Aligned Non Duplicated Coverage`))
head(low_coverage)
low_coverage %>% lm(`Total Sequence` ~ `Aligned Non Duplicated Coverage`, data=.)
superheroes <-
c("    name, alignment, gender,         publisher",
" Magneto,       bad,   male,            Marvel",
"   Storm,      good, female,            Marvel",
"Mystique,       bad, female,            Marvel",
"  Batman,      good,   male,                DC",
"   Joker,       bad,   male,                DC",
"Catwoman,       bad, female,                DC",
" Hellboy,      good,   male, Dark Horse Comics")
superheroes <- read.csv(text = superheroes, strip.white = TRUE)
head(superheroes)
publishers <-
c("publisher, yr_founded",
"       DC,       1934",
"   Marvel,       1939",
"    Image,       1992")
publishers <- read.csv(text = publishers,
strip.white = TRUE)
ijsp = inner_join(superheroes, publishers)
ijsp
ljsp = left_join(superheroes, publishers)
ljsp
fjsp <- full_join(superheroes, publishers)
gjsp
fjsp
fjsp <- full_join(superheroes, publishers)
fjsp
fjsp <- full_join(superheroes, publishers)
ijsp = inner_join(superheroes, publishers) # only one column is in both ("publisher"), so this "publisher" is the
ijsp
class(superheroes)
summary(superheroes)
class(superheroes$publisher)
class(publisher$publisher)
class(publishers$publisher)
levels(publishers$publisher)
levels(superheroes$publisher)
install.packages(‘babynames’)
install.packages(‘pryr’)
install.packages(c("babynames", "pryr"))
library(babynames)
library(pryr)
install.packages("tidyr")
library(babynames)
library(pryr)
View(babynames)
str(babynames)
object_size(babynames)
my_db <- src_sqlite("my_db.sqlite3",
create = T)
babys_sqlite <- copy_to(my_db,
babynames, temporary = FALSE)
src_tbls(my_db)
tbl(my_db,"babynames")
newtbl = my_db %>%
tbl("babynames")%>%
filter(name=="Hilary") %>%
select(year,n,name)
newtbl
output = newtbl %>% collect() # *entire* result
output = newtbl %>% collect() # *entire* result so
output
my_db %>%
tbl("babynames")%>%
filter(name=="Hilary") %>%
select(year,n,name) %>%
summarize(n=n())
popular = babynames %>%
group_by(name) %>%
summarise(N = sum(n)) %>%
arrange(desc(N)) %>% top_n(100)
popular
head(babynames)
popular = babynames %>%
group_by(name) %>%
summarise(N = sum(n)) %>%
arrange(desc(N)) %>% top_n(100)
popular
popular = my_db %>%
tbl(“babynames”)%>%
group_by(name) %>%
summarise(N = sum(n)) %>%
arrange(desc(N)) %>% top_n(100)
popular = my_db %>%
tbl(“babynames”) %>%
group_by(name) %>%
summarise(N = sum(n)) %>%
arrange(desc(N)) %>% collect() %>% top_n(100)
head(babynames)
my_db %>%
tbl("babynames")%>%
filter(name=="Hilary") %>%
select(year,n,name) %>%
summarize(n=n())
# popular baby names
popular = babynames %>%
group_by(name) %>%
summarise(N = sum(n)) %>%
arrange(desc(N)) %>% top_n(100)
# gives ab error (top_n() not supported for this database because we didn't collect first)
popular = my_db %>%
tbl(“babynames”) %>%
group_by(name) %>%
summarise(N = sum(n)) %>%
arrange(desc(N)) %>% top_n(100)
popular = my_db %>%
tbl("babynames") %>%
group_by(name) %>%
summarise(N = sum(n)) %>%
arrange(desc(N)) %>% top_n(100)
popular
popular = my_db %>%
tbl("babynames") %>%
group_by(name) %>%
summarise(N = sum(n)) %>%
arrange(desc(N)) %>% collect() %>% top_n(100)
# fixing the error (but used collect(), which might be dangerous if it's too big)
popular = my_db %>%
tbl("babynames") %>%
group_by(name) %>%
summarise(N = sum(n)) %>%
arrange(desc(N)) %>% collect() %>% top_n(100)
popular
translate_sql(filter(name=="James"))
translate_sql(mean(x))
# translating R code into SQL
translate_sql(filter(name=="James"))
translate_sql(mean(x))
how_female = my_db %>%
tbl("babynames") %>%
group_by(name) %>%
summarize(m=mean(sex=="F"))
explain(how_female)
how_female = my_db %>%
tbl("babynames") %>%
group_by(name) %>%
summarize(m=mean(sex=="F"))
how_female
# what percentage of babies with each name are female?
how_female = my_db %>%
tbl("babynames") %>%
group_by(name) %>%
summarize(m=mean(sex=="F"))
how_female
popular_girls = my_db %>%
tbl("babynames") %>%
filter(sex == "F") %>%
group_by(name) %>%
summarise(N = sum(n)) %>%
arrange(desc(N)) %>% collect() %>% top_n(100)
popular_girls
popular_girls
class(popular_girls)
as.data.frame(popular_girls)
data.frame(popular_girls)
data.frame(popular_girls)
install.packages(c("data.table", "readr"))
library(data.table)
library(readr)
write_csv(babynames,
file="babynames.csv")
write_csv(babynames,
path="babynames.csv")
baby_dt = fread('babynames.csv')
class(baby_dt)
female = baby_dt[sex=="F"]
dim(female)
baby_dt[sex=="F",.(n,name,prop)]
baby_dt[sex=="F",.(name,mean(prop))]
baby_dt[sex=="F",
.(name,mean(prop)),name]
baby_dt[sex=="F",
.(name,aveprop=mean(prop)),name]
baby_dt[,aveprop:=mean(prop),name]
head(baby_dr)
head(baby_dt)
head(baby_dt)
baby_dt[,aveprop:=mean(prop),name] # the ":=" updates the baby_dt object even though we didn't do assignment on the LHS (fast/memory-efficient way to update variable definitions)
head(baby_dt)
baby_dt[sex=="F",.(name,mean(prop))]
baby_dt[sex=="F",
.(name,mean(prop)),name]
baby_dt[sex=="F",
.(name,aveprop=mean(prop)),name]
baby_dt[,aveprop:=mean(prop),name] # the ":=" updates the baby_dt object even though we didn't do assignment on the LHS (fast/memory-efficient way to update variable definitions)
head(baby_dt)
library("Matrix", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
x = c(rep(0, 100), 1)
class(rle(x))
set.seed(34)
x = rnorm(10000)
datList = replicate(10000, sample(1:10000),simplify = FALSE)
class(datList)
system.time(lapply(datList,cor,x))
system.time(mclapply(datList, cor, x))
install.packages("multicore")
install.packages("doParallel")
suppressPackageStartupMessages(library(doParallel))
system.time(foreach(i=1:10000) %do% cor(datList[[i]],x))
system.time(foreach(i=1:10000) %dopar% cor(datList[[i]],x))
registerDoParallel(cores=4)
system.time(foreach(i=1:10000) %dopar% cor(datList[[i]],x))
registerDoParallel(cores=3)
system.time(foreach(i=1:10000) %dopar% cor(datList[[i]],x))
registerDoParallel(cores=4)
system.time(foreach(i=1:10000) %dopar% cor(datList[[i]],x))
datMat = simplify2array(datList)
class(datMat)
dim(datMat)
system.time(cor(x,datMat))
class(datList)
awkCall = "awk -F\"\t\" '$2 == \"chr21\" { print $0 }' foo.txt"
read.delim(pipe(awkCall),header=FALSE)
library(GEOquery)
theData = getGEO(“GSE28521”)[[1]]
theData = getGEO("GSE28521")[[1]]
testing <- c("hfg12hfk", "fghd2", "jdkasd")
grep("h*", testing)
testing <- c("h", "hh", "hhh", "j")
grep("h", testing)
grep("*h*", testing)
grep("h*", testing)
testing <- c("hello", "hello1234", "hello12345")
grep("hello", testing, fixed=TRUE)
testing <- c("hello", "hello1234", "hello12345", "hellohello")
grep("hello", testing, fixed=TRUE)
grep("asdfhello", testing, fixed=TRUE)
testing <- c("asdfhello", "hello1234", "hello12345", "hellohello")
grep("hello", testing, fixed=TRUE)
testing <- c("asdfhello", "hello1234", "hello12345", "hellohello", "hi")
grep("hello", testing, fixed=TRUE)
grep("h*ello", testing, fixed=TRUE)
grep("h*", testing, fixed=TRUE)
grep("h", testing, fixed=TRUE)
grep("*h*", testing, fixed=TRUE)
c("h", "hh", "adh")
grep("h", c("h", "hh", "adh"))
regexpr("h", c("h", "hh", "adh"))
testing <- "apple red ac"
gsub("apple", "", testing)
gsub("apple", "", testing, fixed=TRUE)
gsub("apple", "", testing)
gsub(c("apple", "ac"), "", testing)
gsub("apple", "", testing)
gsub("apple", "", "apple red ac")
gsub("apple", "", "apple red ac")
gsub("ac", "", "apple red ac")
gsub("^a", "", "apple red ac")
c("apple", "red", "ac")
grep("^a", c("apple", "red", "ac"))
testing <- c("apple", "red", "ac")
testing[grep("^a", c("apple", "red", "ac"))] <- "d"
testing
?str_split
library(stringr)
?str_split
str_split("apple red ac", " ")
str_split("apple red ac", " ", simplify=TRUE)
one <- c("apple red ac")
two <- c("banana red ac")
grep(^a, c(one, two))
grep("^a", c(one, two))
grep("^a", one)
one
one
temp2 <- c("dpple", "red", "dc")
paste(temp2, collapse=" ")
ls()
library(msm)
install.packages("caret")
install.packages("ModelMetrics")
library(survival)
library(flexsurv)
library(survMisc) # for Wilcoxon-Gehan-Breslow test
addicts <- read.csv(file="Data/addicts.csv", header=TRUE)
surv.addicts <- Surv(time=addicts$time, event=addicts$event, type="right")
survfit.addicts <- survfit(surv.addicts ~ 1, data=addicts, conf.type = "log-log")
install.packages("muhaz")
library(muhaz)
install.packages("fastAdaboost")
install.packages("adabag")
install.packages("wSVM")
install.packages("dummy")
install.packages("sas7bdat")
install.packages("BioPET")
install.packages('VGAM')
require(devtools)
install.packages('devtools')
cran_downloads(when = "last-week", packages = c("ggplot2", "httr"))
library(devtools)
devtools::install_github("metacran/cranlogs")
instal.packages("dlstats")
install.packages("dlstats")
my.data <- data.frame("age"=rnorm(20), "male"=rbinom(20, 1, 0.5))
my.data
View(my.data)
my.data <- data.frame("age"=runif(20, min=30, max=60), "male"=rbinom(20, 1, 0.5))
boxplot(age ~ male, data=my.data)
boxplot(age ~ male, data=my.data, ylab="age", xlab="indicator of male")
boxplot(age ~ male, ylab="age", xlab="indicator of male")
my.data <- data.frme("age"=runif(100, 30, 60), "male"=rbinom(30, size=1, prob=0.5))
my.data <- data.frame("age"=runif(100, 30, 60), "male"=rbinom(30, size=1, prob=0.5))
my.data <- data.frame("age"=runif(100, 30, 60), "male"=rbinom(100, size=1, prob=0.5))
View(my.data)
my.data <- data.frame("age"=runif(100, 30, 60), "sex"=rbinom(100, size=1, prob=0.5))
boxplot(my.data$age ~ my.data$sex, names=c("Males", "Females"))
boxplot(my.data$age ~ my.data$sex, names=c("Males", "Females"), ylab="Difference")
boxplot(my.data$age ~ my.data$sex, names=c("Males", "Females"), ylab="Difference between 2-week and baseline HiQ")
boxplot(my.data$age ~ my.data$sex, names=c("Males", "Females"), ylab="Diff. between 2-week and baseline")
boxplot(my.data$age ~ my.data$sex, names=c("Males", "Females"), ylab="Diff. between 2-week and baseline", main="males")
my.data <- data.frame("age"=runif(n=50, min=30, max=60), female=rbinom(n=50, size=1, prob=0.5), arm=rbinom(n=50, size=1, prob=0.5))
ppois(5, lambda=5)
1 - ppois(5, lambda=5)
1 - ppois(1/100, lambda=1/100)
1 - ppois(1/100, lambda=100)
1 - ppois(x=5, lambda=5)
1 - ppois(q5, lambda=5)
1 - ppois(q=5, lambda=5)
1 - ppois(q=(1/100), lambda=(1/100))
1 - ppois(q=5, lambda=5)
1 - ppois(9, 5)
pnorm(1)
ppois(1)
1 - ppois(2, 1)
1 - ppois(9, 5)
1 - pnorm(9, mean=5, sd=sqrt(5))
1 - ppois(900, 500)
1 - ppois(900, 800)
1 - ppois(900, 850)
1 - pnorm(9, mean=850, sd=sqrt(850))
1 - pnorm(900, mean=850, sd=sqrt(850))
1 - ppois(900, 850)
1 - ppois(9, 5)
1 - pnorm(9, mean=5, sd=sqrt(5))
1 - pnorm(9+0.5, mean=5, sd=sqrt(5))
1 - pnorm(9-0.5, mean=5, sd=sqrt(5))
1 - pnorm(9, mean=5, sd=sqrt(5))
1 - ppois(9, 5)
1 - pnorm(10, mean=5, sd=sqrt(5))
1 - pnorm(10+0.5, mean=5, sd=sqrt(5))
1 - pnorm(10-0.5, mean=5, sd=sqrt(5))
1 - pnorm(10, mean=5, sd=sqrt(5))
1 - ppois(9, 5)
pnorm(-1.65)
pnorm(-1.65)
qnorm(p=0.05)
qt(p=0.05)
qt(df=11, p=0.05)
qt(df=100000, p=0.05)
qt(df=11, p=0.05)
qt(df=11, p=0.05)
qt(df=3, p=0.05)
qt(df=5, p=0.05)
qt(df=5, p=0.025)
t.test(x=1:10, y=5:14, paired=TRUE)
t.test(x=1:10, y=c(2, 3, 5, -1, 2, 0, 9, 2, 1), paired=TRUE)
t.test(x=1:10, y=c(2, 3, 5, -1, 2, 0, 9, 2, 1, 0), paired=TRUE)
names(t.test(x=1:10, y=c(2, 3, 5, -1, 2, 0, 9, 2, 1, 0), paired=TRUE))
t.test(x=1:10, y=c(2, 3, 5, -1, 2, 0, 9, 2, 1, 0), paired=TRUE)$estimate
t.test(x=1:10, y=c(2, 3, 5, -1, 2, 0, 9, 2, 1, 0), paired=TRUE)$statistic
t.test(x=1:10, y=c(2, 3, 5, -1, 2, 0, 9, 2, 1, 0), paired=TRUE)$parameter
t.test(x=1:10, y=c(2, 3, 5, -1, 2, 0, 9, 2, 1, 0), paired=TRUE)$data.name
t.test(x=1:10, y=c(2, 3, 5, -1, 2, 0, 9, 2, 1, 0), paired=TRUE)$conf.int
-2.58 - 1.79 * 3.09 / sqrt(12)
-2.58 + 1.79 * 3.09 / sqrt(12)
0.2/5*1.96
1 - 0.2/5*1.96
0.94 / .09
(.94 - .67)/.09
project <- read.csv("~/Dropbox/UW/Classes/Winter2019/BIOST537/Grading/Project/bmt.csv", header=TRUE)
rm(list=ls())
bmt <- read.csv("~/Dropbox/UW/Classes/Winter2019/BIOST537/Grading/Project/bmt.csv", header=TRUE)
names(bmt)
table(bmt$disgroup, bmt$fab)
corr(bmt$disgroup, bmt$fab)
cor(bmt$disgroup, bmt$fab)
table(bmt$mtx, bmt$hospital)
table(bmt$hospital, bmt$mtx)
corr(bmt$disgroup, bmt$fab)
table(bmt$disgroup, bmt$fab)
head(bmt)
summary(bmt$age)
library(survival)
devtools::document()
library(DevTreatRules)
head(example_df)
set.seed(123)
example.split <- SplitData(data=example_df, n.sets=3, split.proportions=c(0.5, 0.25, 0.25))
table(example.split$partition)
development.data <- example.split %>% filter(partition == "development")
validation.data <-  example.split %>% filter(partition == "validation")
evaluation.data <-  example.split %>% filter(partition == "evaluation")
library(dplyr)
development.data <- example.split %>% filter(partition == "development")
validation.data <-  example.split %>% filter(partition == "validation")
evaluation.data <-  example.split %>% filter(partition == "evaluation")
names.influencing.treatment=c("prognosis", "clinic", "age")
names.influencing.rule=c("age", paste0("gene_", 1:10))
one.rule <- BuildRule(data=development.data,
study.design="observational",
prediction.approach="split.regression",
name.outcome="no_relapse",
type.outcome="binary",
desirable.outcome=TRUE,
name.treatment="intervention",
names.influencing.treatment=c("prognosis", "clinic", "age"),
names.influencing.rule=c("age", paste0("gene_", 1:10)),
propensity.method="logistic.regression",
rule.method="glm.regression")
set.seed(123)
model.selection <- CompareRulesOnValidation(development.data=development.data,
validation.data=validation.data,
study.design.development="observational",
vec.approaches=c("split.regression", "OWL.framework", "direct.interactions"),
vec.rule.methods=c("glm.regression", "lasso", "ridge"),
vec.propensity.methods="logistic.regression",
name.outcome.development="no_relapse",
type.outcome.development="binary",
name.treatment.development="intervention",
names.influencing.treatment.development=c("prognosis", "clinic", "age"),
names.influencing.rule.development=c("age", paste0("gene_", 1:10)),
desirable.outcome.development=TRUE)
model.selection$list.summaries[["split.regression"]]
model.selection$list.summaries[["OWL.framework"]]
model.selection$list.summaries[["direct.interactions"]]
rule.split <- model.selection$list.rules$split.regression[["propensity_logistic.regression_rule_glm.regression"]]
coef(rule.split$rule.object.control)
coef(rule.split$rule.object.treat)
rule.OWL <- model.selection$list.rules$OWL.framework[["propensity_logistic.regression_rule_glm.regression"]]
coef(rule.OWL$rule.object)
set.seed(123)
split.eval <- EvaluateRule(data=evaluation.data,
BuildRule.object=rule.split,
study.design="observational",
name.outcome="no_relapse",
type.outcome="binary",
desirable.outcome=TRUE,
name.treatment="intervention",
names.influencing.treatment=c("prognosis", "clinic", "age"),
names.influencing.rule=c("age", paste0("gene_", 1:10)),
propensity.method="logistic.regression",
bootstrap.CI=FALSE)
split.eval[c("n.test.positives", "n.test.negatives", "ATE.test.positives", "ATE.test.negatives", "ABR")]
set.seed(123)
OWL.framework.eval <- EvaluateRule(data=evaluation.data,
BuildRule.object=rule.OWL,
study.design="observational",
name.outcome="no_relapse",
type.outcome="binary",
desirable.outcome=TRUE,
name.treatment="intervention",
names.influencing.treatment=c("prognosis", "clinic", "age"),
names.influencing.rule=c("age", paste0("gene_", 1:10)),
propensity.method="logistic.regression",
bootstrap.CI=FALSE)
OWL.framework.eval[c("n.test.positives", "n.test.negatives", "ATE.test.positives", "ATE.test.negatives", "ABR")]
load("/home/jeremy/Dropbox/UW/RA/Autumn_2015/Enrichment/BioPET/data/dcaData.rda")
library(DevTreatRules)
library("DevTreatRules", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
remove.packages("DevTreatRules", lib="~/R/x86_64-pc-linux-gnu-library/3.2")
library("DevTreatRules", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
head(example_df)
setwd("~/Dropbox/UW/Research/Dissertation")
library(devtools)
library(roxygen2)
devtools::document("DevTreatRules")
devtools::install("DevTreatRules")
library(DevTreatRules)
BuildRule
setwd("~/Dropbox/UW/Research/Dissertation")
# (after documented/installed from above in previous session)
library(DevTreatRules)
devtools::check("DevTreatRules")
#devtools::build_win("BioPET")
devtools::release("DevTreatRules")
#devtools::build_win("BioPET")
devtools::release("DevTreatRules")
#devtools::build_win("BioPET")
devtools::release("DevTreatRules")
#devtools::build_win("BioPET")
devtools::release("DevTreatRules")
install.packages("hunspell")
install.packages("~/Downloads/hunspell_2.9.tar.gz", repos = NULL, type = "source")
#devtools::build_win("BioPET")
devtools::release("DevTreatRules")
devtools::build_win("BioPET")
devtools::build_win("DevTreatRules")
rm(list=ls())
library(devtools)
library(roxygen2)
# (after documented/installed from above in previous session)
library(DevTreatRules)
#devtools::build_win("BioPET")
devtools::release("DevTreatRules")
setwd("~/Dropbox/UW/Research/Dissertation")
#devtools::build_win("BioPET")
devtools::release("DevTreatRules")
use_cran_comments()
use_cran_comments
install.packages("usethis")
install.packages("~/Downloads/usethis_1.1.0.tar.gz", repos = NULL, type = "source")
library(usethis)
use_cran_comments()
getwd("DevTreatRules/")
setwd("DevTreatRules/")
use_cran_comments()
